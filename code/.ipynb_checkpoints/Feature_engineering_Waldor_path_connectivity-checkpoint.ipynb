{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering process Waldor"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "In Part 1 we will download data like we do in public_baseline. For this data we will calculate features after.\n",
    "In Part 2 we will start feature engineering - make some functions for calculating some generated features.\n",
    "In Part 3 we write modified feature_engineering function -> we add one new argumnet - w2v.\n",
    "In Part 4 we will do a feature_engineering to have all features we will use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries that we will use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dinar\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import preprocessing\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "import nltk\n",
    "import csv\n",
    "import igraph\n",
    "import math\n",
    "\n",
    "from read_data import *\n",
    "from graph_creation import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialization like in public_baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\dinar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\dinar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "creating graph\n",
      "graph created\n"
     ]
    }
   ],
   "source": [
    "# ---First Initializations--- #\n",
    "path_to_data = \"../data/\"\n",
    "nltk.download('punkt')  # for tokenization\n",
    "nltk.download('stopwords')\n",
    "stpwds = set(nltk.corpus.stopwords.words(\"english\"))\n",
    "stemmer = nltk.stem.PorterStemmer()\n",
    "\n",
    "# ---Read Data--- #\n",
    "testing_set, training_set, node_info = read_data()\n",
    "IDs = [element[0] for element in node_info]\n",
    "\n",
    "# ---Create graph--- #\n",
    "g = create_graph(training_set, IDs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional to public_baseline graph features "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) shortest_path and edge_connectivity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create the full NON directed graph of relations between the abstracts to calculate the shortest path and the edge sonnectivity using igraph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only one time\n",
    "def undirected_graph(information_set, IDs):\n",
    "    edges = [(element[0], element[1]) for element in information_set if element[2]==\"1\"]\n",
    "    print(edges[0], edges[100], edges[100000])\n",
    "    nodes = IDs\n",
    "\n",
    "    print (\"Edges and nodes for undirected graph prepared.\")\n",
    "    graph = igraph.Graph(directed=False)\n",
    "    graph.add_vertices(nodes)\n",
    "    graph.add_edges(edges)\n",
    "\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function to calculate a shortest edge FOR ONE RECORD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shortest_path_edge_connectivity(shortest_path, edge_connectivity, edge, graph, source, target):\n",
    "    index_source = IDs.index(source)\n",
    "    index_target = IDs.index(target)\n",
    "    if (edge == \"1\"):\n",
    "        graph.delete_edges([(source,target)])\n",
    "        val = graph.shortest_paths_dijkstra(source=index_source, target=index_target)[0][0]\n",
    "        edge_connectivity.append(graph.edge_disjoint_paths(source=index_source, target=index_target))\n",
    "        shortest_path.append(val)\n",
    "        graph.add_edges([(source,target)])\n",
    "    else:\n",
    "        val = graph.shortest_paths_dijkstra(source=index_source, target=index_target)[0][0]\n",
    "        edge_connectivity.append(graph.edge_disjoint_paths(source=index_source, target=index_target))\n",
    "        shortest_path.append(val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean function from feture_engineering.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(s, stemmer, stpwds):\n",
    "    s = s.lower().split(\" \")\n",
    "    s = [token for token in s if token not in stpwds]\n",
    "    s = [stemmer.stem(token) for token in s]\n",
    "    s = [''.join([elt for elt in token if not elt.isdigit()]) for token in s] # remove digits\n",
    "    s = [token for token in s if len(token)>2] # remove tokens shorter than 3 characters in size\n",
    "    s = [token for token in s if len(token)<=25] # remove tokens exceeding 25 characters in size\n",
    "    return s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature_engineering function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def first_step (information_set, node_info, IDs) :\n",
    "    # Undirected graph to calculate shortest_path and edge_connectivity\n",
    " #   graph = undirected_graph(information_set, IDs)\n",
    "  #  print (\"Undirected graph created.\")\n",
    "   # print (\"First step finished.\\n\")\n",
    "    #return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('9510123', '9502114') ('205265', '105095') ('101119', '1082')\n",
      "Edges and nodes for undirected graph prepared.\n",
      "27770 335130\n"
     ]
    }
   ],
   "source": [
    "edges = [(element[0], element[1]) for element in training_set if element[2]==\"1\"]\n",
    "print(edges[0], edges[100], edges[100000])\n",
    "nodes = IDs\n",
    "\n",
    "print (\"Edges and nodes for undirected graph prepared.\")\n",
    "graph = igraph.Graph(directed=False)\n",
    "graph.add_vertices(nodes)\n",
    "graph.add_edges(edges)\n",
    "\n",
    "print(len(graph.vs), len(graph.es))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "335130"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forth_step(information_set, IDs, node_info, stemmer, stpwds, g, TEST):\n",
    "    # shortest path between the nodes of abstract graph\n",
    "    shortest_path = []\n",
    "    edge_connectivity = []\n",
    "    \n",
    "    # More useful variables\n",
    "    counter = 0\n",
    "    degrees = g.degree(IDs)\n",
    "    neighbors_list = []\n",
    "    for id in IDs:\n",
    "        neighbors_list.append(set(g.neighbors(id)))\n",
    "        \n",
    "    print (\"Forth step - start to calculate features.\")\n",
    "        \n",
    "    #### ---- Calculating features ---- ####\n",
    "    for i in range(len(information_set)):\n",
    "        source = information_set[i][0]\n",
    "        target = information_set[i][1]\n",
    "        if TEST :\n",
    "            edge = 0\n",
    "        else:\n",
    "            edge = information_set[i][2]\n",
    "            \n",
    "        index_source = IDs.index(source)\n",
    "        index_target = IDs.index(target)\n",
    "        \n",
    "     #   if source == '105155' and target == '9806044':\n",
    "      #      counter += 1\n",
    "       #     continue\n",
    "            \n",
    "        if (edge == \"1\"):\n",
    "            graph.delete_edges([(index_source, index_target)])\n",
    "            val = graph.shortest_paths_dijkstra(source=index_source, target=index_target)[0][0]\n",
    "            edge_connectivity.append(graph.edge_disjoint_paths(source=index_source, target=index_target))\n",
    "            shortest_path.append(val)\n",
    "            graph.add_edges([(source,target)])\n",
    "        else:\n",
    "            val = graph.shortest_paths_dijkstra(source=index_source, target=index_target)[0][0]\n",
    "            edge_connectivity.append(graph.edge_disjoint_paths(source=index_source, target=index_target))\n",
    "            shortest_path.append(val)\n",
    "\n",
    "      ##  shortest_path_edge_connectivity(shortest_path, edge_connectivity, edge, graph, source, target)\n",
    "\n",
    "        counter += 1\n",
    "        if counter % 500 == 0:\n",
    "            print (\"\\t\\t\\t\", counter, \"examples processed\")\n",
    "    \n",
    "    print (\"4 step - All features calculated\")\n",
    "\n",
    "    #### ---- Final features array ---- ####\n",
    "    list_of_features.append(shortest_path)\n",
    "    list_of_features.append(edge_connectivity)\n",
    "        \n",
    "    return list_of_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate features and save it in files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Commun part for trainig and testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('9510123', '9502114') ('205265', '105095') ('101119', '1082')\n",
      "Edges and nodes for undirected graph prepared.\n",
      "Undirected graph created.\n",
      "First step finished.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#graph = first_step (training_set, node_info, IDs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train features calculating.\n"
     ]
    }
   ],
   "source": [
    "print(\"Train features calculating.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train= []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forth step - start to calculate features.\n",
      "9510123 9502114 1\n",
      "9707075 9604178 1\n",
      "9312155 9506142 0\n",
      "9911255 302165 0\n",
      "9701033 209076 0\n",
      "9710020 9709228 1\n",
      "9901042 9510135 1\n",
      "209146 9502077 0\n",
      "9705079 9702201 1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-89-0a0d2991395e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m## Forth step ##\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mfeatures\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mforth_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_set\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIDs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnode_info\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstemmer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstpwds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-88-f16bafb44723>\u001b[0m in \u001b[0;36mforth_step\u001b[1;34m(information_set, IDs, node_info, stemmer, stpwds, g, TEST)\u001b[0m\n\u001b[0;32m     33\u001b[0m             \u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdelete_edges\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex_source\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex_target\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m             \u001b[0mval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshortest_paths_dijkstra\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindex_source\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindex_target\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m             \u001b[0medge_connectivity\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0medge_disjoint_paths\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindex_source\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindex_target\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m             \u001b[0mshortest_path\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m             \u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_edges\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## Forth step ##\n",
    "features = forth_step(training_set, IDs, node_info, stemmer, stpwds, g, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert list of lists into array\n",
    "# Documents as rows, unique words as columns (i.e., example as rows, features as columns)\n",
    "training_features = np.array(features).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale\n",
    "#training_features = preprocessing.scale(training_features)\n",
    "np.save(path_to_data + 'shortest_path_edge_connectivity_train.npy', training_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Testing set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Test features calculating.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_test= []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Forth step ##\n",
    "features_test = forth_step(testing_set, IDs, node_info, stemmer, stpwds, g, graph, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert list of lists into array\n",
    "# Documents as rows, unique words as columns (i.e., example as rows, features as columns)\n",
    "testing_features = np.array(features_test).T\n",
    "# Scale\n",
    "#testing_features = preprocessing.scale(testing_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(path_to_data + 'shortest_path_edge_connectivity_test.npy', testing_features)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
